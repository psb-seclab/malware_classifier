from os.path import getsize
from math import log
import numpy as np
import re
from numba import jit, int32, float64

class Sample(object):
    """A Sample represents a file whose contents can be parsed for features.
    
    When created, the sample reads in and stores all of the contents of the
    file in order to optimize the speed of the parsing.
    
    On top of holding the contents of the file, the Sample class can also
    maintain a cache of pertinent information in order to optimize the 
    performance of feature parsing by preventing duplicated logic. This can
    be used like so:
    
        sample = Sample('...')
        sample['Lines'] = sample._file_contents.split()
        if ('Lines' in sample):
        
            print(sample['Lines'])
    
    This class utilizes the following cache values:
    
        'WCount_{word}':  The number of instances found for the word {word} in 
                          the file.
        'Lines':          A list of all of the lines in the file.
        'Words_{regex}':  A list of all of the words in the file split using
                          the regex {regex}.
        
    """
    
    # Initialize a static cache to store values that may need to be reused
    # by all instances of the class.
    __cache = {}
    
    def __init__(self, file_name):
        """Initialize a new sample whose contents can be found in the file
        pointed to by the specified file path.
        """
        
        # Save the file name.
        self._file_name = file_name
        
        # Ensure the file is valid.
        try:
            with open(file_name, 'rb') as file:
                # Store the contents of the file for parsing.
                self._file_contents = file.read()
                
        except IOError:
            raise ValueError('Invalid file name %s' % file_name)
            
        # Initialize a cache to store values that may need to be reused.
        self.__cache = {}
        
    def __contains__(self, key):
        """Check if the cache contains an item for the specified key."""
        return key in self.__cache
        
    def __delitem__(self, key):
        """Clear the cached item with the specified key."""
        self.__cache.pop(key, None)
            
    def __getitem__(self, key):
        """Get the cached value for the specified key."""
        return self.__cache[key]
        
    def __setitem__(self, key, value):
        """Set the cached value for the specified key."""
        self.__cache[key] = value
        
    def file_size(self):
        """Get the size of the file."""
        return getsize(self._file_name)
        
    def lines(self):
        """Get the lines in the file."""
        
        # Cache the lines in the file.
        if (not 'Lines' in self):
            self['Lines'] = self._file_contents.split(b'\n')
            
        return self['Lines']
    
    @staticmethod
    def load_list(list_file_name):
        """Load and return all of the lines from the specified files as a list.
        
        Once a list is loaded from a file, the list is cached for subsequent
        calls.
        """
        
        # If the list is not in the cache, load in the file.
        if (not list_file_name in Sample.__cache):
            try:
                with open(list_file_name, 'rb') as file:
                    Sample.__cache[list_file_name] = file.read().split(b'\r\n')
            except IOError:
                raise IOError('Could not load the file %s' % list_file_name)
                
        return Sample.__cache[list_file_name]
        
    def num_lines(self):
        """Get the number of lines in the file."""
        return len(self.lines())
        
    def word_counts(self, *words, split_pattern=rb''):
        """Find the number of occurrences of the specified words.
        
        Each word must be bytes or bytes-like, not a string. You can convert
        a string literal to bytes by prepending a lowercase b before the
        quotation marks like so:
        
            b'Hello'
            
        If you wish to split the words in a file a certain way, you can
        specify the split_pattern as a bytes object containing a regex that
        will be used to split the file contents into a list of words.
        
        The return value will be a list of counts with each count corresponding
        to the passed in word.
        """
        
        # Find the word whose results are not already cached.
        uncached_words = set()
        for word in words:
            
            # Ensure the word's result is not cache'd.
            word_key = 'WCount_%s' % word
            if word_key in self:
                continue
            
            # Add the word to the set.
            uncached_words.add(word)
            
            # Initialize the word's count in the cache.
            self[word_key] = 0
            
        # If there are uncached patterns, they need to be counted.
        if uncached_words:
            
            # Retrieve all of the words in the file.
            #file_words = self.words()
            file_words = self.words(split_pattern) if split_pattern \
                                                   else self.words()
            
            # Iterate through every word in the file. If a word is in the
            # list of uncached words, increment its count.
            for word in file_words:
                if word and word in uncached_words:
                    word_key = 'WCount_%s' % word
                    self[word_key] += 1
        
        # Return a list of all of the counts.
        return [self['WCount_%s' % word] for word in words]
        
    def words(self, split_pattern=rb'\s+'):
        """Get the words in the file.
        
        The split_pattern is a regex string that will determine how the word
        boundaries are defined. The regex string matches whitespace by default.
        """
        
        # Cache the words in the file.
        key = 'Words_%s' % split_pattern
        if (not key in self):
            
            # Split the file contents into words.
            self[key] = re.split(split_pattern, self._file_contents)
            
        return self[key]
    
        
class ExeAsmSample(Sample):
    """An ExeAsmSample represents the assembly file for a Windows executable
    program.
    
    Since this class is a subclass of the Sample class, the ExeAsmSample has
    access to the Sample's caching features. Along with those used in the
    Sample class, this class uses the following cache values:
    
        'Opcodes': The list of opcodes whose counts in the file are used as
                   features.
                   
    """
    
    # Regex pattern used for splitting the file when counting registers.
    registers_split = rb'\s+|\,+|\[+|\]+|\++|\-+|\*+|\:+'
    
    def __init__(self, asm_file_name):
        """Initialize a new Windows Executable sample whose assembly file can
        be found at the specified file path.
        """
        # Call base constructor.
        super(ExeAsmSample, self).__init__(asm_file_name)
        
    def api_features(self):
        """Retrieve the frequency of the top 794 most frequent APIs used in 
        malicious files in list form.
        
        Each element of this list will show how many of each API is used.
        
        Files containing no APIs are highly suspicious.
        """
        
        api_list = self.apis()
        
        lines = self._hex_contents.split(b'\n')
        
        counts = {key: 0 for key in api_list}
        for i in api_list:
            for j in lines:
                if bytes(i, 'utf-8') in j:
                    counts[i] = counts.get(i, 0) + 1
        return counts.values()
        
    def features(self):
        """Get a list of features extracted from the assembly file.
        
        The list of features will have the following format:
        
            [ { Metadata Features (2) }, { Symbol Features (7) }, { Opcode Counts (93) }, 
              { Register Counts (26 ) }, { Section Features (24) }, { Data Define Features (24) }  ]
              
        """
        
        # Optimization: The word_counts method counts all of the words passed
        #               to it in only one pass through the file. This means
        #               that it is faster to count every word at once rather
        #               than splitting them among multiple calls. Since the
        #               word_counts method caches all of its results for
        #               subsequent calls, we can count everything at once to
        #               store all the results to the cache, which will be
        #               immediately retrieved when the feature methods call
        #               the word_count method again.
        #
        #               This is a tested optimization. It consistently saves
        #               about a fifth of a second, which can save about an
        #               hour when expanded to 20,000 samples.
        self.word_counts(*(ExeAsmSample.opcodes() + ExeAsmSample.registers()),
                         split_pattern=ExeAsmSample.registers_split)
                         
        features = []
        features += self.metadata_features()
        features += self.symbol_features()
        features += self.opcode_features()
        features += self.register_features()
        features += self.section_features()
        features += self.data_define_features()
        return features
        
    def metadata_features(self):
        """Get a list of metadata features from the file.
        
        The feature list will have the following format:
        
        [ { File Size }, { Line Count }]
        """
        return [self.file_size(), self.num_lines()]
        

    def misc_features(self):
        """Retrieve the frequency of 95 manually chosen keywords used in 
        malicious files in list form.
        
        Each element of the list is related to different trends in malware
        files. For example, 'dll' is used to show the number of imported dll's
        """
        
        misc_list = self.miscs()
        
        lines = self._hex_contents.split(b'\n')
        
        counts = {key: 0 for key in misc_list}
        for i in misc_list:
            for j in lines:
                if bytes(i, 'utf-8') in j:
                    counts[i] = counts.get(i, 0) + 1
        return counts.values()
        
    def opcode_features(self):
        """Get a list of counts for all of the predefined opcodes in the file.
        
        The list of counts will correspond to the list of opcodes found in
        opcodes.txt.
        """
        
        # Measure the counts of each of the opcodes.
        return self.word_counts(*ExeAsmSample.opcodes())
        
    def register_features(self):
        """Get a list of counts for all of the predefined registers in the
        file.
        
        The list of counts will correspond to the list of registers found in
        registers.txt.
        """
                            
        # Registers can often be grouped with brackets, colons, commas, and
        # mathematical operators. These will need to be filtered out.
        return self.word_counts(*ExeAsmSample.registers(), 
                                split_pattern=ExeAsmSample.registers_split)
    
    @staticmethod
    def apis():
        """Returns a list of all of the apis who counts in the file should be
        used as features
        """
        
        return Sample.load_list('apis.txt')
    
    @staticmethod
    def miscs():
        """Returns a list of 75 manually chosen keywords whos counts in the
        file should be used as features
        """
        
        return Sample.load_list('misc.txt')
    
    @staticmethod
    def opcodes():
        """Return a list of all of the opcodes whose counts in the file should
        be used as features.
        """
        
        # The opcodes should be stored in a file called 'opcodes.txt'
        return Sample.load_list('opcodes.txt')
        
    @staticmethod
    def registers():
        """Return a list of all of the registers whose counts in the file
        should be used as features.
        """
        
        # The registers should be stored in a file called 'registers.txt'
        return Sample.load_list('registers.txt')

    @staticmethod
    def symbols():
        """Return a list of all of the symbols whose counts in the file 
        should be used as features. 
        """
        
        # The symbols should be stored in a file called 'symbols.txt'
        return Sample.load_list('symbols.txt')
    
    @staticmethod
    def sections():
        """Return a list of all of the sections whose counts in the file 
        should be used as features. 
        """
        
        # The symbols should be stored in a file called 'sections.txt'
        return Sample.load_list('sections.txt')
        
    @staticmethod
    def datadefine():
        """Return a list of all of the datadefine whose counts in the file 
        should be used as features. 
        """
        
        # The symbols should be stored in a file called 'datadefine.txt'
        return Sample.load_list('datadefine.txt')

    def symbol_features(self):
        """Returns an list count of symbols: -, +, *, [, ], ?, @
        
        [ { -, +, *, [, ], ?, @  } ]
        """
        
        #creates a dictionary with symbol values
        symCount = { symbol: 0 for symbol in self.symbols() }
        
        #loops through the file and searches for each 
        #symbol and adds 1 for each find
        for char in self._file_contents:
            if(bytes([char]) in symCount):
                symCount[bytes([char])] += 1
        
        return [symCount[symbol] for symbol in self.symbols()]
        
        
        
    def unkLines(self):
        """Returns the number of unkLines
        """
        
        # Check if the result is already cached.
        if 'unkLines' not in self:
            
            knownLines = 0
            
            for sec in self.section_counts():
                knownLines += sec
                
            self['unkLines'] = self.num_lines() - knownLines
            
        return self['unkLines']
    
    def section_counts(self):
        """Returns a list of section and unknown section counts
        """

        # Cache the lines in the file.
        if (not 'secCount' in self):
            sectionCount = { section: 0 for section in self.sections() }   
            #loops through the file and searches for each 
            #section and adds 1 for each find
            for sec in self.lines():
                if(sec in sectionCount):
                    sectionCount[sec] += 1
            self['secCount'] = self.word_counts(*self.sections(), split_pattern=b':.*(\n|$)')
        
        return self['secCount']
        
    def unkSection_counts(self):
        """Returns a list of unknown counts
        """
        
        if('unkSecCount' not in self):
            sectionCount = { section: 0 for section in self.sections() }        
            
            sectionUnk = set()
            sectionsUnk = dict()                    
            
            unkLines = 0            
            #loops through the file and searches for each 
            #section and adds 1 for each find
            for sec in self.lines():
                if(sec not in sectionCount):
                    unkLines += 1
                    x = 0
                    #gets the unknown section name from .to the before :
                    #add the unknown section to a set, which only allows unique values
                    sectionUnk.add(sec.split(b':',1)[0])
                    #loop through array and search for unknown sections
                    tempL = list(sectionUnk)
                    while x != len(sectionUnk):
                        tempStr = '\\' + str(tempL[x])
                        if(re.search(bytes(tempStr, 'utf-8'), sec) is not None):
                            sectionsUnk[x] = sectionsUnk.get(x,0) + 1
                        x += 1
                        
            self['unkSecCount'] = len(sectionsUnk)
            
        return self['unkSecCount']
    
    def section_features(self):
        """Returns a list of known and unknown sections count and proportions
        
        [ { .bss, .data, .edata, .idata, .rdata, .rsrc, .text, .tls, .reloc, 
        totalSections, totalUnkSections, totalLinesUnkSections, 
        knownSectionPorp, unkSectionProp, unkSectionPropW, 
        bssProp, dataProp, edataProp, idataProp, rdataProp, 
        rsrcProp, textProp, tlsProp, relocProp} ]
        """
        
        #total number of sections
        numSection = len([section for section in self.section_counts() if section != 0]) + self.unkSection_counts()
        #total number of unknown sections
        unkSection = self.unkSection_counts()
        #total number of lines in unknown sections
        #proportion of unknown sections to the all sections
        unkSecProp = self.unkSection_counts()/numSection
        #proportion of known sections to the all section
        knownSecProp = 1 - unkSecProp
        #The proportion of the amount of unknown sections to the whole file
        unkProp = self.unkLines()/self.num_lines()
        #proportion of .bss section to the whole file
        bssProp = self.section_counts()[0]/self.num_lines()
        #proportion of .data section to the whole file
        dataProp = self.section_counts()[1]/self.num_lines()
        #proportion of .edata section to the whole file
        edataProp = self.section_counts()[2]/self.num_lines()
        #proportion of .idata section to the whole file
        idataProp = self.section_counts()[3]/self.num_lines()
        #proportion of .rdata section to the whole file
        rdataProp = self.section_counts()[4]/self.num_lines()
        #proportion of .rsrc section to the whole file
        rsrcProp = self.section_counts()[5]/self.num_lines()
        #proportion of .text section to the whole file
        textProp = self.section_counts()[6] /self.num_lines()
        #proportion of .tls section to the whole file
        tlsProp = self.section_counts()[7]/self.num_lines()
        #proportion of .reloc section to the whole file
        relocProp = self.section_counts()[8]/self.num_lines()
        
        secFeatures = []
        secFeatures.extend((self.section_counts()[0], self.section_counts()[1], self.section_counts()[2], self.section_counts()[3], self.section_counts()[4], self.section_counts()[5], self.section_counts()[6], self.section_counts()[7], self.section_counts()[8]))
        secFeatures.extend((numSection, unkSection, self.unkLines(), knownSecProp, unkSecProp, unkProp,))        
        secFeatures.extend((bssProp, dataProp, edataProp, idataProp, rdataProp, rsrcProp, textProp, tlsProp, relocProp))
        
        return secFeatures
        
    def data_define(self):
        """Returns a list of db, dd, dw counts
        """        
        """
        dataDefineCount = { dade: 0 for dade in self.sections() }  
        for opcode in self.lines():
            if(opcode in dataDefineCount):
                dataDefineCount[opcode] += 1
            
            
            print(ExeAsmSample.sections())
            #loops through the file and searches for each 
            #section and adds 1 for each find
            for sec in self.lines():
                if(sec in sectionCount):
                    sectionCount[sec] += 1
            self['secCount'] = self.word_counts(*self.sections(), split_pattern=b':.*(\n|$)')
        
        return self['secCount']        
        """
    def data_define_features(self):
        """Returns a list of db, dd, dw count and proportions
        [ {  } ]        
        
        """

        dbCount = 0
        ddCount = 0
        dwCount = 0
        #count of db with 0 parameter whole files
        db0w = 0
        #count of db with not 0 parameter whole file
        #dbNotw = 0
        #count of db in text section
        dbtext = 0
        #count of dd in text section
        ddtext = 0
        #count of count of dd in rdata section
        ddrdata = 0
        #count of db with 1 non 0 parameter in rdata section
        db10rdata = 0
        #count of db with 1 non 0 parameter in data section
        db10data = 0
        #count of db with 1 non 0 parameter in idata section
        db10idata = 0
        #count of db with 1 non 0 parameter in unknown section
        db10Unk = 0
        #count of db with 1 non 0 parameter whole file
        db10w = 0
        #count of dd with 4 parameters
        dd4 = 0
        #count of dd with 5 parameters
        dd5 = 0
        #count of dd with 6 parameters
        dd6 = 0
        #count of dd with 4 parameters in unknown section
        dd4Unk = 0
        #count of dd with 5 parameters in unknown section
        dd5Unk = 0
        #count of dd with 6 parameters in unknown section
        dd6Unk = 0
        #count of dd with 4 parameters whole file
        dd4w = 0
        #count of dd with 5 parameters whole file
        dd5w = 0
        #count of dd with 6 parameters whole file
        dd6w = 0
        """
        
        for instruct in self.lines():  
            if(re.search(b'\.bss', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                
            elif(re.search(b'\.data', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                        db10data += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                        
            elif(re.search(b'\.edata', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                
            elif(re.search(b'\.idata', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                        db10data += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                    
            elif(re.search(b'\.rdata', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                        db10rdata += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    ddrdata += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                    
            elif(re.search(b'\.rsrc', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                
            elif(re.search(b'\.text', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    dbtext += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    ddtext += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                
            elif(re.search(b'\.tls', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                
            elif(re.search(b'\.reloc', instruct) is not None):
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                    
                elif(re.search(b' dd ', instruct) is not None):
                    ddCount += 1
                    temp1 = instruct.split(b',')
                    if(len(temp1) == 4):
                        dd4 += 1
                    if(len(temp1) == 5):
                        dd5 += 1
                    if(len(temp1) == 6):
                        dd6 += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                
            else:
                if(re.search(b' db ', instruct) is not None):
                    dbCount += 1
                    temp = re.sub(b' +',b' ',instruct).split(b' ')
                    dbP = temp.index(b'db') + 1
                    if(temp[dbP] == b'0\r\n'):
                        db0w += 1
                    else:
                        db10w += 1
                        db10Unk += 1
                elif(re.search(b' dd ', instruct) is not None):
                    if(len(temp1) == 4):
                        dd4Unk += 1
                    if(len(temp1) == 5):
                        dd5Unk += 1
                    if(len(temp1) == 6):
                        dd6Unk += 1
                    
                elif(re.search(b' dw ', instruct) is not None):
                    dwCount += 1            
                """
        
        #loop through each line search for db, dd, dw and get parameters
        for instruct in self.lines():
            #db parameters
            if(re.search(b' db ', instruct) is not None):
                dbCount += 1
                temp = re.sub(b' +',b' ',instruct).split(b' ')
                dbP = temp.index(b'db') + 1
                if(temp[dbP] == b'0\r\n'):
                    db0w += 1
                else:
                    db10w += 1
                    if(re.search(b'\.rdata', instruct) is not None):
                        db10rdata += 1
                    elif(re.search(b'\.data', instruct) is not None):
                        db10data += 1
                    elif(re.search(b'\.idata', instruct) is not None):
                        db10idata += 1
                    elif(re.search(b'\.bss|\.edata|\.rsrc|\.tls|\.reloc', instruct) is None):
                        db10Unk += 1
                if(re.search(b'\.text', instruct) is not None):
                    dbtext += 1
            if(re.search(b' dd ', instruct) is not None):
                ddCount += 1
                temp1 = instruct.split(b',')
                if(len(temp1) == 4):
                    dd4 += 1
                if(len(temp1) == 5):
                    dd5 += 1
                if(len(temp1) == 6):
                    dd6 += 1
                if(re.search(b'\.text', instruct) is not None):
                    ddtext += 1
                elif(re.search(b'\.rdata', instruct) is not None):
                    ddrdata += 1
                elif(re.search(b'\.bss|\.edata|\.rsrc|\.tls|\.reloc|\.idata', instruct) is None):
                    if(len(temp1) == 4):
                        dd4Unk += 1
                    if(len(temp1) == 5):
                        dd5Unk += 1
                    if(len(temp1) == 6):
                        dd6Unk += 1
            if(re.search(b' dw ', instruct) is not None):
                dwCount += 1
        
        dd4w = dd4 + dd4Unk
        dd5w = dd5 + dd5Unk
        dd6w = dd6 + dd6Unk
        dbCount - db10w / dbCount        
        
        #proportion of db instructions in the whole file
        dbwProportion = dbCount / self.num_lines()
        
        #proportion of dd instruction in the whole file
        ddwProportion = ddCount / self.num_lines()
        
        #proportion of dw instruction in the whole file
        dwwProportion = dwCount / self.num_lines()
        
        #proportion of all db, dd, and dw instructions in the whole file
        allProportion = (dbCount + ddCount + dwCount) / self.num_lines()
        
        #proportion of db instruction with 0 parameter in the whole file
        db0wProportion = db0w / self.num_lines()
        
        #proportion of db instruction with not 0 parameter in the whole file
        dbNotwProportion = (dbCount - db0w) / dbCount
        
        #proportion of dd instruction in the text section
        ddtextProportion = ddtext / self.section_counts()[6] if self.section_counts()[6] > 0 else 0
        
        #proportion of db instruction in the text section
        dbtextProportion = dbtext / self.section_counts()[6] if self.section_counts()[6] > 0 else 0
        
        #proportion of dd instruction in the rdata section
        ddrdataProportion = ddrdata / self.section_counts()[4] if self.section_counts()[4] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the rdata section
        db10rdataProportion = db10rdata / self.section_counts()[4] if self.section_counts()[4] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the data section
        db10dataProportion = db10data / self.section_counts()[6] if self.section_counts()[6] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the idata section
        db10idataProportion = db10idata / self.section_counts()[3] if self.section_counts()[3] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in unknown sections
        db10UnkProportion = db10rdata / self.unkLines()  if self.unkLines() > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the whole file
        db10wProportion = db10w / self.num_lines()
        
        #proportion of dd instruction with 4 parameters
        #dd4
        
        #proportion of dd instruction with 5 parameters
        #dd5
        
        #proportion of dd instruction with 6 parameters
        #dd6
        
        #proportion of dd instruction with 4 parameters in the whole file
        dd4wProportion = dd4w / self.num_lines()
        
        #proportion of dd instruction with 5 parameters in the whole file
        dd5wProportion = dd5w / self.num_lines()
        
        #proportion of dd instruction with 6 parameters in the whole file
        dd6wProportion = dd6w / self.num_lines()
        
        #proportion of dd instruction with 4 parameters in unknown sections
        dd4UnkProportion = dd4Unk / self.unkLines() if self.unkLines() > 0 else 0
        
        #proportion of dd instruction with 5 parameters in unknown sections
        dd5UnkProportion = dd5Unk / self.unkLines() if self.unkLines() > 0 else 0
        
        #proportion of dd instruction with 6 parameters in unknown sections
        dd6UnkProportion = dd6Unk / self.unkLines() if self.unkLines() > 0 else 0
        
        #proportion of db instruction with 0 parameter to db instruction with non 0 parameter
        dd0NotProportion = db0w / self.num_lines()
        
        datadefine = []
        
        #add to feature list 7
        datadefine.extend((dbwProportion, ddwProportion, dwwProportion, allProportion, db0wProportion, dbNotwProportion))
        datadefine.extend((ddtextProportion, dbtextProportion, ddrdataProportion, db10rdataProportion, db10dataProportion, db10idataProportion, db10UnkProportion, db10wProportion))
        datadefine.extend((dd4, dd5, dd6, dd4wProportion, dd5wProportion, dd6wProportion, dd4UnkProportion, dd5UnkProportion, dd6UnkProportion , dd0NotProportion))
        
        #print out statements for features 7
        return datadefine

def entropy(counts, window_size):
    """Retrieve the entropy for a window with the specified counts and window
    sizes.
    
    The counts should be a list of the counts for each of the distinct items
    in the window.
    
    The return value will be between 0 (order) and 8(randomness).
    """
    
    entropies = [count / window_size * log(count / window_size, 2) for count 
                 in counts if count > 0]
    
    return -sum(entropies)
        
class ExeHexSample(Sample):
    """An ExeSample represents a malware sample.
    
    Every malware sample must contain a hexadecimal dump. With that provided,
    the sample can be analyzed and have various features extracted from it.
    
    In addition to the cached attributes in the Sample class, this class
    defines the following addition cached values:
    
        'Bytes':   The list of bytes in the file.
        'Strings': The list of strings in the file.
    """
            
    def bytes(self):
        """Return a list of all bytes contained in the hex file for the sample.
        
        Each byte is represented by its decimal value. The special ?? byte is
        represented with a value of -1.
        """
        
        # Parse the hex bytes from the file if they have not been parsed yet.
        if (not 'Bytes' in self):
            
            # Remove all spaces from the contents of the file.
            contents = b''.join(self._file_contents.split())
            
            # Every two hex digits represents a single byte.
            byte_values = [-1 if contents[i:i+2] == b'??' 
                           else int(contents[i:i+2], 16) 
                           for i in range(0, len(contents), 2)]
                               
            # Cache the bytes.
            self['Bytes'] = byte_values
            
        return self['Bytes']
    
    def entropies(self, window_size=10000):
        """Calculate the entropy values for each of the windows in the hex
        file if the window has the specified size.
        
        A list of all of the entropy values calculated for each window will
        be returned.
        """
        
        hex_bytes = self.bytes()
        
        # Ensure there are enough bytes for at least one window.
        if (len(hex_bytes) < window_size):
            raise ValueError(('The window size {0} exceeds the number ' +
                             'of bytes in the file: {1}')
                             .format(window_size, len(hex_bytes)))
                             
        # Retrieve the byte counts for the first window.
        window = hex_bytes[:window_size]
        
        byte_counts = {byte: 0 for byte in range(-1, 256)}
        for byte in window:
            byte_counts[byte] += 1
        
        # Calculate the entropy for the first window.
        current_entropy = entropy(byte_counts.values(), window_size)
        entropy_values = [current_entropy]
        
        # Add the entropy values for the rest of the windows.
        for i in range(1, len(hex_bytes) - window_size):
            
            # Determine which bytes were removed and added.
            removed_byte = hex_bytes[i-1]
            added_byte = hex_bytes[i+window_size]
            
            # If the added and removed bytes are not the same, the entropy 
            # needs to be adjusted.
            if (removed_byte != added_byte):
                                
                # Subtract out the old entropy values for the modified bytes.
                modified_counts = [byte_counts[removed_byte], 
                                   byte_counts[added_byte]]
                current_entropy -= entropy(modified_counts, window_size)
                
                # Adjust the counts.
                byte_counts[removed_byte] -= 1
                byte_counts[added_byte] += 1
                
                # Add the new entropy values for the modified bytes.
                modified_counts = [byte_counts[removed_byte], 
                                   byte_counts[added_byte]]
                current_entropy += entropy(modified_counts, window_size)
                
            # Add the entropy value to the list.
            entropy_values.append(current_entropy)
            
        return entropy_values
        
    def entropy_features(self, window_size=10000):
        """Retrieve statistics for the entropy values collected from the
        hex file.
        
        The list of stats returned are in the following format:
        
            [ { mean }, { variance }, { standard deviation }, 
              { Percentiles 0 - 100 } ]
        """
        
        # Retrieve the list of entropy values.
        entropy_values = self.entropies(window_size)
        
        # Calculate various statistics for the entropy values.
        stats = [
            np.mean(entropy_values),
            np.var(entropy_values),
            np.std(entropy_values),
        ]
        
        # Percentiles 0 - 100
        for i in range(101):
            stats.append(np.percentile(entropy_values, i))
            
        return stats
        
                
    def features(self):
        """Return a feature vector containing all of the features retrieved 
        from the hex file of the sample.
        
        The format of the feature vector is as follows (the numbers in
        parenthesis indicate how many features are in each section):
        
        [ { 1-gram frequencies (256) }, { hex file metadata (2) }, 
          { hex file entropy (105) }, { string length distribution (16) } ]
        """
        
        features = []
        
        features += self.one_gram_features()
        features += self.metadata_features()
        features += self.entropy_features()
        features += self.entropies(len(self.bytes()))
        features += self.string_features()
        
        return features
        
    def first_address(self):
        """Return the address of the first byte sequence in the sample's
        hex file.
        """
        
        # The first word in the hex file is the address of the first byte 
        # sequence.
        first_word = self._file_contents[:8]
        
        # The address is a hexadecimal value. Convert it to decimal.
        return int(first_word, 16)
            
    def metadata_features(self):
        """Return a feature vector containing metadata related features
        extracted from the sample's hex dump.
        
        The feature vector will have the following format:
        
        [ {file size (bytes)}, {1st byte sequence address (decimal)} ]
        """
        return [self.file_size(), self.first_address()]
        
    def strings(self):
        """Return a list of all strings in the file.
        
        Strings are determined by taking by converting all of the bytes in the
        file to their ASCII equivalent characters and separating the sequence
        of characters on "unreadable" characters. In ASCII, characters in the
        range of 32 - 127 are considered readable.
        """
        
        # Check the cache for the saved strings first.
        if ('Strings' not in self):
            
            # Retrieve all of the bytes in the hex file.
            bytes = self.bytes()
            
            # The first four bytes of every 20 bytes contains an address, which
            # should not be analyzed to find a string.
            bytes = [bytes[i] for i in range(len(bytes)) if i % 20 >= 4]
            
            # Convert the hex values to decimal values.
            # NOTE: The ?? bytes are useless. Filter them out.
            ascii_values = [byte for byte in bytes if byte != -1]
            
            # The printable range for ASCII characters is 32 - 127. Replace
            # anything outside those bounds with a null to be filtered out.
            characters = [chr(value) if 32 <= value <= 127 else '\0' for value 
                          in ascii_values]
                          
            # Retrieve each string by splitting up sequences of characters by
            # null characters.
            strings = ''.join(characters)
            strings = [string for string in strings.split('\0') 
                       if string != '']
            
            # Cache the strings.
            self['Strings'] = strings
            
        return self['Strings']
        
    def string_features(self, *bins):
        """Returns a histogram containing the count of all of the strings in
        each specified bin.
        
        The bins parameter should be a list of tuples containing 2 integers
        that define the range for each bin. The first number of each tuple
        should define the lower range (inclusive) and the second number should
        define the higher range (exclusive).
        
        On top of the specified bins, there will always be a bin countaining
        the count of all strings that didn't fall into any other bins. The
        count for this bin will be the last value in the returned list.
        """
        
        # Default bin_boundaries:
        if (not bins):
            bins = [(0, 10), (10, 30), (30, 60), (60, 90), (0, 100),
                    (100, 150), (150, 250), (250, 400), (400, 600), (600, 900),
                    (900, 1300), (1300, 2000), (2000, 3000), (3000, 6000), 
                    (6000, 150000)]
                    
        # If there were specific bin values passed, ensure they are structured
        # correctly.
        else:
            
            # Validate each bin.
            for bin in bins:
                
                # Ensure each item is a tuple.
                if (type(bin) is not tuple):
                    raise TypeError('Bins must be represented with tuples')
                    
                # Ensure each tuple has only two values.
                if (len(bin) != 2):
                    raise ValueError('Bin tuples must contain exactly 2 ints')
                    
                # Ensure both values are integers.
                if (type(bin[0]) is not int or type(bin[1]) is not int):
                    raise TypeError('Bin tuples must contain int values')
                    
        # Convert each bin to a range.
        bins = [range(bin[0], bin[1]) for bin in bins]
        
        # Retrieve all of the strings.
        strings = self.strings()
        
        # Categorize each string into a bin.
        # NOTE: A single string can be classified into multiple bins.
        counts = {bin: 0 for bin in bins}
        uncategorized = 0
        for string in strings:
            
            # Keep track if a string is categorized into at least one bin.
            categorized = False
            
            # Check if the string fits in each bin.
            for bin in bins:
                
                # Count the string if its length fits in the range of the bin.
                if len(string) in bin:
                    counts[bin] += 1
                    
                # Mark the bin as categorized.
                categorized = True
                
            # Check if the string was uncategorized.
            if (not categorized):
                uncategorized += 1
                
        # Return the count for every bin.
        counts = [counts[bin] for bin in bins]
        counts.append(uncategorized)
        
        return counts
        
    def one_gram_features(self, *one_grams):
        """Return the list of frequencies in the hex file for every specified
        1-gram value.
        
        A 1-gram has 256 possible values (0 - 255). The list returned will
        contain integer values representing the number of times its respective
        1-gram appeared in the file.
        
        If no argument is specified, the frequencies of all 256 possible 
        1-grams are found. In this scenario, the 1-grams are in ascending 
        order, meaning that 0x00 is at index 0 and 0xFF is at index 255.
        """
        
        # Default one_grams:
        if not one_grams:
            one_grams = range(256)
        
        # Validate one_grams:
        else:
            
            # Type check
            non_ints = sum(type(item) is not int for item in one_grams)
            if (non_ints > 0):
                raise TypeError('1-gram values must be integer values')
                
            # Range check
            invalid_ranges = sum(not 0 <= value <= 255 for value in one_grams)
            if (invalid_ranges > 0):
                raise ValueError('1-grams must be in the range 0 - 255 '
                                 + 'inclusive')
                                                                  
        # Every byte represents a one-gram.
        # NOTE: ?? bytes are ignored.
        file_one_grams = [byte for byte in self.bytes() if byte != -1]
            
        # Retrieve the counts for each one gram.
        counts = {one_gram: 0 for one_gram in one_grams}
        for one_gram in file_one_grams:
            if (one_gram in counts):
                counts[one_gram] += 1
                
        return [counts[one_gram] for one_gram in one_grams]