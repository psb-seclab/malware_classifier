from os.path import getsize
from math import log
import numpy as np
import re
import mahotas
import collections

###############################################################################

def entropy(counts, window_size):
    """Retrieve the entropy for a window with the specified counts and window
    sizes.
    
    The counts should be a list of the counts for each of the distinct items
    in the window.
    
    The return value will be between 0 (order) and 8(randomness).
    """
    
    entropies = [count / window_size * log(count / window_size, 2) for count 
                 in counts if count > 0]
    
    return -sum(entropies)
    
###############################################################################

class Sample(object):
    """A Sample represents a file whose contents can be parsed for features.
    
    When created, the sample reads in and stores all of the contents of the
    file in order to optimize the speed of the parsing.
    
    On top of holding the contents of the file, the Sample class can also
    maintain a cache of pertinent information in order to optimize the 
    performance of feature parsing by preventing duplicated logic. This can
    be used like so:
    
        sample = Sample('...')
        sample['Lines'] = sample.contents().split()
        if ('Lines' in sample):
        
            print(sample['Lines'])
    
    This class utilizes the following cache values:
    
        'Contents':       The entire file's contents in the form of a string.
        'Lines':          A list of all of the lines in the file.
        'Words_{regex}':  A list of all of the words in the file split using
                          the regex {regex}.
        'WCount_{word}':  The number of instances found for the word {word} in 
                          the file.
        
    """
    
    # Initialize a static cache to store values that may need to be reused
    # by all instances of the class.
    __cache = {}
    
    @staticmethod
    def load_list(list_file_name):
        """Load and return all of the lines from the specified files as a list.
        
        Once a list is loaded from a file, the list is cached for subsequent
        calls.
        """
        
        # If the list is not in the cache, load in the file.
        if (not list_file_name in Sample.__cache):
            try:
                with open(list_file_name, 'rb') as file:
                    Sample.__cache[list_file_name] = file.read().split(b'\r\n')
            except IOError:
                raise IOError('Could not load the file %s' % list_file_name)
                
        return Sample.__cache[list_file_name]
    
    def __init__(self, file_name):
        """Initialize a new sample whose contents can be found in the file
        pointed to by the specified file path.
        """
        
        # Save the file name.
        self._file_name = file_name
        
        # Initialize a cache to store values that may need to be reused.
        self.__cache = {}
        
        # Ensure the file is valid.
        try:
            with open(file_name, 'rb') as file:
                # Store the contents of the file for parsing.
                self['Contents'] = file.read()
                
        except IOError:
            raise ValueError('Invalid file name %s' % file_name)
                    
    def __contains__(self, key):
        """Check if the cache contains an item for the specified key."""
        return key in self.__cache
        
    def __delitem__(self, key):
        """Clear the cached item with the specified key."""
        self.__cache.pop(key, None)
            
    def __getitem__(self, key):
        """Get the cached value for the specified key."""
        return self.__cache[key]
        
    def __setitem__(self, key, value):
        """Set the cached value for the specified key."""
        self.__cache[key] = value        
        
    def contents(self):
        """Get the entire file as one continuous string."""
        return self['Contents']
        
    def file_size(self):
        """Get the size of the file."""
        return getsize(self._file_name)
        
    def lines(self):
        """Get the lines in the file."""
        
        # Cache the lines in the file.
        if (not 'Lines' in self):
            self['Lines'] = self.contents().split(b'\n')
            
        return self['Lines']
        
    def num_lines(self):
        """Get the number of lines in the file."""
        return len(self.lines())

    def word_counts(self, *words, split_pattern=rb''):
        """Find the number of occurrences of the specified words.
        
        Each word must be bytes or bytes-like, not a string. You can convert
        a string literal to bytes by prepending a lowercase b before the
        quotation marks like so:
        
            b'Hello'
            
        If you wish to split the words in a file a certain way, you can
        specify the split_pattern as a bytes object containing a regex that
        will be used to split the file contents into a list of words.
        
        The return value will be a list of counts with each count corresponding
        to the passed in word.
        """
        
        # Find the word whose results are not already cached.
        uncached_words = set()
        for word in words:
            
            # Ensure the word's result is not cache'd.
            word_key = 'WCount_%s' % word
            if word_key in self:
                continue
            
            # Add the word to the set.
            uncached_words.add(word)
            
            # Initialize the word's count in the cache.
            self[word_key] = 0
            
        # If there are uncached patterns, they need to be counted.
        if uncached_words:
            
            # Retrieve all of the words in the file.
            file_words = self.words(split_pattern) if split_pattern \
                                                   else self.words()
            
            # Iterate through every word in the file. If a word is in the
            # list of uncached words, increment its count.
            for word in file_words:
                if word and word in uncached_words:
                    word_key = 'WCount_%s' % word
                    self[word_key] += 1
        
        # Return a list of all of the counts.
        return [self['WCount_%s' % word] for word in words]
        
    def words(self, split_pattern=rb'\s+'):
        """Get the words in the file.
        
        The split_pattern is a regex string that will determine how the word
        boundaries are defined. The regex string matches whitespace by default.
        """
        
        # Cache the words in the file.
        key = 'Words_%s' % split_pattern
        if (not key in self):
            
            # Split the file contents into words.
            self[key] = [word for word 
                         in re.split(split_pattern, self.contents()) 
                         if word != b'']
            
        return self[key]
        
###############################################################################    
        
class ExeAsmSample(Sample):
    """An ExeAsmSample represents the assembly file for a Windows executable
    program.
    
    Since this class is a subclass of the Sample class, the ExeAsmSample has
    access to the Sample's caching features. Along with those used in the
    Sample class, this class uses the following cache values:
    
        'Opcodes': The list of opcodes whose counts in the file are used as
                   features.
                   
    """
    
    # Regex patterns used for splitting the file when counting various items:
    
    # Whitespace
    api_split = rb'\s+'
    
    # Whitespace, +
    misc_split = rb'[\s:]+' 
    
    # Whitespace, commas, [, ], +, -, *, :
    registers_split = rb'[\s,\[\]+\-*:]+'
    
    # Whitespace
    opcode_split = rb'\s+'
    
    # Everything after (and including) the first colon in each line
    sections_split = b':.*(?:\n+|$)'
    
    @staticmethod
    def apis():
        """Returns a list of all of the apis who counts in the file should be
        used as features
        """
        
        return Sample.load_list('lists/apis.txt')
        
    @staticmethod
    def datadefine():
        """Return a list of all of the datadefine whose counts in the file 
        should be used as features. 
        """
        
        # The symbols should be stored in a file called 'datadefine.txt'
        return Sample.load_list('lists/datadefine.txt')
    
    @staticmethod
    def miscs():
        """Returns a list of 75 manually chosen keywords whos counts in the
        file should be used as features
        """
        
        return Sample.load_list('lists/misc.txt')
    
    @staticmethod
    def opcodes():
        """Return a list of all of the opcodes whose counts in the file should
        be used as features.
        """
        
        # The opcodes should be stored in a file called 'opcodes.txt'
        return Sample.load_list('lists/opcodes.txt')
        
    @staticmethod
    def registers():
        """Return a list of all of the registers whose counts in the file
        should be used as features.
        """
        
        # The registers should be stored in a file called 'registers.txt'
        return Sample.load_list('lists/registers.txt')
        
    @staticmethod
    def sections():
        """Return a list of all of the sections whose counts in the file 
        should be used as features. 
        """
        
        # The symbols should be stored in a file called 'sections.txt'
        return Sample.load_list('lists/sections.txt')

    @staticmethod
    def symbols():
        """Return a list of all of the symbols whose counts in the file 
        should be used as features. 
        """
        
        # The symbols should be stored in a file called 'symbols.txt'
        return Sample.load_list('lists/symbols.txt')
    
    def __init__(self, asm_file_name):
        """Initialize a new Windows Executable sample whose assembly file can
        be found at the specified file path.
        """
        # Call base constructor.
        super(ExeAsmSample, self).__init__(asm_file_name)
        
    def all_sections(self):
        """Get a set of all sections in the file. This includes both known
        and unknown sections.
        """
    
        # Cache value if necessary.
        if (not 'All Sections' in self):
            
            self['All Sections'] = set(self.words(ExeAsmSample.sections_split))
            
        return self['All Sections']
        
    def api_features(self):
        """Retrieve the frequency of the top 794 most frequent APIs used in 
        malicious files in list form.
        
        Each element of this list will show how many of each API is used.
        
        Files containing no APIs are highly suspicious.
        """
        
        api_list = self.apis()
        return self.word_counts(*api_list, 
                                split_pattern=ExeAsmSample.api_split)
        
    def features(self):
        """Get a list of features extracted from the assembly file.
        
        The list of features will have the following format:
        
            [ { Metadata Features (2) }, { Symbol Features (7) }, 
              { Opcode Counts (93) }, { Register Counts (26) },
              { API Counts (794) }, { Section Characteristics (24) }
              { Data Define Features (24) }, { Miscellaneous (95) }  ]
              
        """
        
        # Optimization: The word_counts method counts all of the words passed
        #               to it in only one pass through the file. This means
        #               that it is faster to count every word at once rather
        #               than splitting them among multiple calls. Since the
        #               word_counts method caches all of its results for
        #               subsequent calls, we can count everything at once to
        #               store all the results to the cache, which will be
        #               immediately retrieved when the feature methods call
        #               the word_count method again.
        #
        #               This optimization can be applied for the API's,
        #               miscellaneous keywords, registers, and opcodes.
        #               This optimization cannot be applied to sections due to
        #               the split pattern for sections cutting out most of the
        #               text in the file.
        #
        #               This is a tested optimization. It consistently saves
        #               about a fifth of a second, which can save about an
        #               hour when expanded to 20,000 samples.
        optimizable_words = ExeAsmSample.apis() + ExeAsmSample.miscs() \
                            + ExeAsmSample.registers() + ExeAsmSample.opcodes()
        self.word_counts(*optimizable_words,
                         split_pattern=ExeAsmSample.registers_split)
                         
        features = []
        features += self.metadata_features()
        features += self.symbol_features()
        features += self.opcode_features()
        features += self.register_features()
        features += self.api_features()
        features += self.section_features()
        features += self.data_define_features()
        features += self.misc_features()
        return features
        
    def known_sections(self):
        """Return a set of all of the known sections in the file."""
        
        # Cache the value if necessary.
        if ('Known Sections' not in self):
            
            self['Known Sections'] = set(section for section 
                                         in ExeAsmSample.sections() 
                                         if section in self.all_sections())
                                          
        return self['Known Sections']
        
    def metadata_features(self):
        """Get a list of metadata features from the file.
        
        The feature list will have the following format:
        
        [ { File Size }, { Line Count }]
        """
        return [self.file_size(), self.num_lines()]
        

    def misc_features(self):
        """Retrieve the frequency of 95 manually chosen keywords used in 
        malicious files in list form.
        
        Each element of the list is related to different trends in malware
        files. For example, 'dll' is used to show the number of imported dll's
        """
        
        misc_list = self.miscs()
        
        return self.word_counts(*misc_list, split_pattern = rb'\s+|:+')            
        
    def opcode_features(self):
        """Get a list of counts for all of the predefined opcodes in the file.
        
        The list of counts will correspond to the list of opcodes found in
        opcodes.txt.
        """
        
        # Measure the counts of each of the opcodes.
        return self.word_counts(*ExeAsmSample.opcodes(), 
                                split_pattern=ExeAsmSample.opcode_split)
        
    def register_features(self):
        """Get a list of counts for all of the predefined registers in the
        file.
        
        The list of counts will correspond to the list of registers found in
        registers.txt.
        """
                            
        # Registers can often be grouped with brackets, colons, commas, and
        # mathematical operators. These will need to be filtered out.
        return self.word_counts(*ExeAsmSample.registers(), 
                                split_pattern=ExeAsmSample.registers_split)

    def symbol_features(self):
        """Returns an list count of symbols: -, +, *, [, ], ?, @
        
        [ { -, +, *, [, ], ?, @  } ]
        """
        
        # Create a regex pattern to filter out everything except the symbols.
        symbols = self.symbols()
        regex = b'[^' + re.escape(b''.join(self.symbols())) + b']+'
                                                  
        # Retrieve a list of all of the words split with the pattern.
        words = self.words(regex)
        characters = b''.join(words)
                
        # Count each of the symbols in the string.
        counts = {symbol[0]: 0 for symbol in symbols}
        for char in characters:
            if char in counts:
                counts[char] += 1
                
        return [counts[symbol[0]] for symbol in symbols]
        
    def section_features(self):
        """Return a list of known and unknown sections count and proportions.
        
        The list of features returned is in the following format:
        
            [ .bss, .data, .edata, .idata, .rdata, .rsrc, .text, .tls, 
              .reloc, totalSections, totalUnkSections, totalLinesUnkSections, 
              knownSectionPorp, unkSectionProp, unkSectionPropW, bssProp, 
              dataProp, edataProp, idataProp, rdataProp, rsrcProp, textProp, 
              tlsProp, relocProp ]
        """
        
        features = []
        
        # Line counts for all known sections.
        num_lines_sections = self.section_line_counts()
        features += num_lines_sections
        
        # Total number of sections.
        num_sections = len(self.all_sections())
        features.append(num_sections)
        
        # Total number of unknown sections.
        num_unknown_sections = len(self.unknown_sections())  
        features.append(num_unknown_sections)
        
        # Total number of lines in unknown sections.
        num_lines_unknown = self.unkown_section_line_count()
        features.append(num_lines_unknown)
        
        # Proportion of number of known sections to total number of sections.
        known_all_proportion = len(self.known_sections()) / num_sections
        features.append(known_all_proportion)
                       
        # Proportion of number of unknown sections to total number of sections.
        unknown_all_proportion = num_unknown_sections / num_sections
        features.append(unknown_all_proportion)
        
        # Proportion of unknown lines to total lines in file.
        num_lines_total = self.num_lines()
        unknown_all_lines_proportion = num_lines_unknown / num_lines_total
        features.append(unknown_all_lines_proportion)

        # Proportion of lines in each section to total lines in file.
        sections_all_lines_proportion = [count / num_lines_total for count 
                                         in num_lines_sections]
        features.extend(sections_all_lines_proportion)
        
        return features
        
    def section_line_counts(self):
        """Return a list containing the counts of the number of lines in each
        of the sections retrieved from the static sections() method.
        """

        # Cache the values if necessary.
        if (not 'Section Lines' in self):            
            
            self['Section Lines'] = self.word_counts(*self.sections(),
                                                     split_pattern=\
                                                     self.sections_split)
        
        return self['Section Lines']
        
    def unknown_sections(self):
        """Return a set of all unknown sections in the file."""
        
        # Cache the value if necessary.
        if (not 'Unknown Sections' in self):
            
            # The set of all unknown sections can be determined by cutting
            # the set of known sections from the set of all sections.
            self['Unknown Sections'] = self.all_sections() \
                                       - self.known_sections()
                                       
        return self['Unknown Sections']
        
    def unkown_section_line_count(self):
        """Return the number of lines contained in sections other than the
        ones returned by the static sections() method.
        """
        
        # Check if the result is already cached.
        if ('Unknown Lines' not in self):
            
            # Since every line in the file must belong to a section, we
            # can determine the number of unknown sections by subtracting the
            # number of lines in known sections from the total number of lines
            # in the file.
            self['Unknown Lines'] = self.num_lines() \
                                    - sum(self.section_line_counts())
            
        return self['Unknown Lines']
        
    def data_define_features(self):
        """Returns a list of db, dd, dw count and proportions
        [ {  } ]        
        
        """

        dbCount = 0
        ddCount = 0
        dwCount = 0
        #count of db with 0 parameter whole files
        db0w = 0
        #count of db with not 0 parameter whole file
        #dbNotw = 0
        #count of db in text section
        dbtext = 0
        #count of dd in text section
        ddtext = 0
        #count of count of dd in rdata section
        ddrdata = 0
        #count of db with 1 non 0 parameter in rdata section
        db10rdata = 0
        #count of db with 1 non 0 parameter in data section
        db10data = 0
        #count of db with 1 non 0 parameter in idata section
        db10idata = 0
        #count of db with 1 non 0 parameter in unknown section
        db10Unk = 0
        #count of db with 1 non 0 parameter whole file
        db10w = 0
        #count of dd with 4 parameters
        dd4 = 0
        #count of dd with 5 parameters
        dd5 = 0
        #count of dd with 6 parameters
        dd6 = 0
        #count of dd with 4 parameters in unknown section
        dd4Unk = 0
        #count of dd with 5 parameters in unknown section
        dd5Unk = 0
        #count of dd with 6 parameters in unknown section
        dd6Unk = 0
        #count of dd with 4 parameters whole file
        dd4w = 0
        #count of dd with 5 parameters whole file
        dd5w = 0
        #count of dd with 6 parameters whole file
        dd6w = 0

        #loop through each line search for db, dd, dw and get parameters
        for instruct in self.lines():
            #db parameters
            temp2 = instruct.split(b':')
            if(re.search(b' db ', instruct) is not None):
                dbCount += 1
                temp = re.sub(b' +',b' ',instruct).split(b' ')
                dbP = temp.index(b'db') + 1
                if(temp[dbP] == b'0\r\n'):
                    db0w += 1
                else:
                    db10w += 1
                    if(b'.rdata' == temp2[0]):
                        db10rdata += 1
                    elif(b'.data' == temp2[0]):
                        db10data += 1
                    elif(b'.idata'== temp2[0]):
                        db10idata += 1
                    elif(re.search(b'\.bss|\.edata|\.rsrc|\.tls|\.reloc', temp2[0]) is None):
                        db10Unk += 1
                if(b'.text' == temp2[0]):
                    dbtext += 1
            #dd parameters
            elif(re.search(b' dd ', instruct) is not None):
                ddCount += 1
                temp1 = instruct.split(b',')
                if(len(temp1) == 4):
                    dd4 += 1
                if(len(temp1) == 5):
                    dd5 += 1
                if(len(temp1) == 6):
                    dd6 += 1
                if(b'.text' == temp2[0]):
                    ddtext += 1
                elif(b'.rdata' == temp2[0]):
                    ddrdata += 1
                elif(re.search(b'\.bss|\.edata|\.rsrc|\.tls|\.reloc|\.idata', temp2[0]) is None):
                    if(len(temp1) == 4):
                        dd4Unk += 1
                    if(len(temp1) == 5):
                        dd5Unk += 1
                    if(len(temp1) == 6):
                        dd6Unk += 1
            #dw parameters
            elif(re.search(b' dw ', instruct) is not None):
                dwCount += 1      
        
        dd4w = dd4 + dd4Unk
        dd5w = dd5 + dd5Unk
        dd6w = dd6 + dd6Unk
        
        num_lines = self.num_lines()        
        
        #proportion of db instructions in the whole file
        dbwProportion = dbCount / num_lines
        
        #proportion of dd instruction in the whole file
        ddwProportion = ddCount / num_lines
        
        #proportion of dw instruction in the whole file
        dwwProportion = dwCount / num_lines
        
        #proportion of all db, dd, and dw instructions in the whole file
        allProportion = (dbCount + ddCount + dwCount) / num_lines
        
        #proportion of db instruction with 0 parameter in the whole file
        db0wProportion = db0w / num_lines
        
        #proportion of db instruction with not 0 parameter in the whole file
        dbNotwProportion = (dbCount - db0w) / dbCount if dbCount > 0 else 0
        
        section_counts = self.section_line_counts()
        
        #proportion of dd instruction in the text section
        ddtextProportion = ddtext / section_counts[6] if section_counts[6] > 0 else 0
        
        #proportion of db instruction in the text section
        dbtextProportion = dbtext / section_counts[6] if section_counts[6] > 0 else 0
        
        #proportion of dd instruction in the rdata section
        ddrdataProportion = ddrdata / section_counts[4] if section_counts[4] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the rdata section
        db10rdataProportion = db10rdata / section_counts[4] if section_counts[4] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the data section
        db10dataProportion = db10data / section_counts[6] if section_counts[6] > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the idata section
        db10idataProportion = db10idata / section_counts[3] if section_counts[3] > 0 else 0
        
        unknown_lines = self.unkown_section_line_count()        
        
        #proportion of db instruction with 1 non 0 parameter in unknown sections
        db10UnkProportion = db10rdata / unknown_lines if unknown_lines > 0 else 0
        
        #proportion of db instruction with 1 non 0 parameter in the whole file
        db10wProportion = db10w / num_lines
        
        #proportion of dd instruction with 4 parameters
        #dd4
        
        #proportion of dd instruction with 5 parameters
        #dd5
        
        #proportion of dd instruction with 6 parameters
        #dd6
        
        #proportion of dd instruction with 4 parameters in the whole file
        dd4wProportion = dd4w / num_lines
        
        #proportion of dd instruction with 5 parameters in the whole file
        dd5wProportion = dd5w / num_lines
        
        #proportion of dd instruction with 6 parameters in the whole file
        dd6wProportion = dd6w / num_lines
        
        #proportion of dd instruction with 4 parameters in unknown sections
        dd4UnkProportion = dd4Unk / unknown_lines if unknown_lines > 0 else 0
        
        #proportion of dd instruction with 5 parameters in unknown sections
        dd5UnkProportion = dd5Unk / unknown_lines if unknown_lines > 0 else 0
        
        #proportion of dd instruction with 6 parameters in unknown sections
        dd6UnkProportion = dd6Unk / unknown_lines if unknown_lines > 0 else 0
        
        #proportion of db instruction with 0 parameter to db instruction with non 0 parameter
        dd0NotProportion = db0w / num_lines
        
        datadefine = []
        
        #add to feature list 7
        datadefine.extend((dbwProportion, ddwProportion, dwwProportion, allProportion, db0wProportion, dbNotwProportion))
        datadefine.extend((ddtextProportion, dbtextProportion, ddrdataProportion, db10rdataProportion, db10dataProportion, db10idataProportion, db10UnkProportion, db10wProportion))
        datadefine.extend((dd4, dd5, dd6, dd4wProportion, dd5wProportion, dd6wProportion, dd4UnkProportion, dd5UnkProportion, dd6UnkProportion , dd0NotProportion))
        
        #print out statements for features 7
        return datadefine    
        
class ExeHexSample(Sample):
    """An ExeSample represents a malware sample.
    
    Every malware sample must contain a hexadecimal dump. With that provided,
    the sample can be analyzed and have various features extracted from it.
    
    In addition to the cached attributes in the Sample class, this class
    defines the following addition cached values:
    
        'Bytes':   The list of bytes in the file.
        'Strings': The list of strings in the file.
    """
            
    def bytes(self):
        """Return a list of all bytes contained in the hex file for the sample.
        
        Each byte is represented by its decimal value. The special ?? byte is
        represented with a value of -1.
        """
        
        # Parse the hex bytes from the file if they have not been parsed yet.
        if (not 'Bytes' in self):
            
            # Remove all spaces from the contents of the file.
            contents = b''.join(self.contents().split())
            
            # Every two hex digits represents a single byte.
            byte_values = [-1 if contents[i:i+2] == b'??' 
                           else int(contents[i:i+2], 16) 
                           for i in range(0, len(contents), 2)]
                               
            # Cache the bytes.
            self['Bytes'] = byte_values
            
        return self['Bytes']
        
    def digits(self):
        """ """
        
        if (not 'Digits' in self):
            
            # Remove all spaces from the contents of the file.
            contents = b''.join(self.contents().split())
            
            digits = [-1 if digit == ord('?') 
                            else int(chr(digit), 16) 
                           for digit in contents]
                               
            self['Digits'] = digits
            
        return self['Digits']
        
    def image_array(self):
        """Create and return an image array containing a list of grayscale
        pixels generated from each hex digit in the file.
        """
        
        # Check if the image array is cached.
        if ('Image' in self):
            return self['Image']
            
        # Retrieve all of the hex digits in the list.
        # NOTE: ? digits are interpreted as having a value of 0.
        digits = self.digits()
        imgarray = [0 if digit == -1 else digit for digit in digits]
        
        # Each line in a bytes file contains 40 digits. The last line of the
        # file, however, may contain less than 40 digits. In order to create
        # a non-jagged 2D array, we need to reduce the number of pixels to the
        # largest multiple of 40.
        lines = len(imgarray) // 40
        imgarray = imgarray[:lines*40]
        
        # Reshape the array of pixels into a 2D array containing 40 columns
        # and a number of rows equivalent to the number of rows in the file
        # (potentially minus 1 row).
        imgarray = np.reshape(imgarray, (lines, 40))        
            
        # Turn the list into a numpy array.
        imgarray = np.array(imgarray)
        
        # Cache the image array.
        self['Image'] = imgarray
        
        return imgarray
        
    def local_binary_pattern_features(self):
        """Retrieve the local binary pattern features from an image
        representation of the file.
        """
        
        # Retrieve an image representation of the file.
        img = self.image_array()
        
        # Find the 13 Local Binary Pattern features from the image.
        lbppoints = mahotas.features.lbp(img, 10, 10, ignore_zeros=False)
        
        return lbppoints.tolist()
        
    def haralick_features(self):
        """Retrieve the haralick features from an image representation of the
        file.
        """
    
        # Retrieve an image representation of the file.
        img = self.image_array()
        
        # Run Haralick features analysis on the image.
        features = mahotas.features.haralick(img)
        return list(features.flatten())
        
    def entropies(self, window_size=10000):
        """Calculate the entropy values for each of the windows in the hex
        file if the window has the specified size.
        
        A list of all of the entropy values calculated for each window will
        be returned.
        """
        
        hex_bytes = self.bytes()
        
        # Ensure there are enough bytes for at least one window.
        if (len(hex_bytes) < window_size):
            raise ValueError(('The window size {0} exceeds the number ' +
                             'of bytes in the file: {1}')
                             .format(window_size, len(hex_bytes)))
                             
        # Retrieve the byte counts for the first window.
        window = hex_bytes[:window_size]
        
        byte_counts = {byte: 0 for byte in range(-1, 256)}
        for byte in window:
            byte_counts[byte] += 1
        
        # Calculate the entropy for the first window.
        current_entropy = entropy(byte_counts.values(), window_size)
        entropy_values = [current_entropy]
        
        # Add the entropy values for the rest of the windows.
        for i in range(1, len(hex_bytes) - window_size):
            
            # Determine which bytes were removed and added.
            removed_byte = hex_bytes[i-1]
            added_byte = hex_bytes[i+window_size]
            
            # If the added and removed bytes are not the same, the entropy 
            # needs to be adjusted.
            if (removed_byte != added_byte):
                
                removed_count = byte_counts[removed_byte]
                added_count = byte_counts[added_byte]
                                
                # Subtract out the old entropy values for the modified bytes.
                p = removed_count / window_size
                if (p > 0):
                    current_entropy += p * log(p, 2)
                                
                p = added_count / window_size
                if (p > 0):
                    current_entropy += p * log(p, 2)
                
                # Adjust the counts.
                removed_count -= 1
                added_count += 1
                
                # Add the new entropy values for the modified bytes.
                p = removed_count / window_size
                if (p > 0):
                    current_entropy -= p * log(p, 2)
                
                p = added_count / window_size
                if (p > 0):
                    current_entropy -= p * log(p, 2)
                    
                byte_counts[removed_byte] = removed_count
                byte_counts[added_byte] = added_count
                
            # Add the entropy value to the list.
            entropy_values.append(current_entropy)
            
        return entropy_values        
        
    def entropy_features(self, window_size=10000):
        """Retrieve statistics for the entropy values collected from the
        hex file.
        
        The list of stats returned are in the following format:
        
            [ { mean }, { variance }, { standard deviation }, 
              { Percentiles 0 - 100 } ]`
        """
        
        # Retrieve the list of entropy values.
        entropy_values = self.entropies(window_size)
        
        # Calculate various statistics for the entropy values.
        stats = [
            np.mean(entropy_values),
            np.var(entropy_values),
            np.std(entropy_values),
        ]
        
        # Percentiles 0 - 100
        stats.extend(np.percentile(entropy_values, i) for i in range(101))
            
        return stats
        
                
    def features(self):
        """Return a feature vector containing all of the features retrieved 
        from the hex file of the sample.
        
        The format of the feature vector is as follows (the numbers in
        parenthesis indicate how many features are in each section):
        
        [ { 1-gram frequencies (256) }, { hex file metadata (2) }, 
          { hex file entropy (105) }, { image representation features (160) }
          { string length distribution (16) } ]
          
        """
        
        features = []
        
        features += self.one_gram_features()
        features += self.metadata_features()
        features += self.entropy_features()
        features += self.entropies(len(self.bytes()))
        features += self.image_features()
        features += self.string_features()
        
        return features
        
    def first_address(self):
        """Return the address of the first byte sequence in the sample's
        hex file.
        """
        
        # The first word in the hex file is the address of the first byte 
        # sequence.
        first_word = self.contents()[:8]
        
        # The address is a hexadecimal value. Convert it to decimal.
        return int(first_word, 16)
        
    def image_features(self):
        """Return a list of features retrieved from analyzing an image 
        representation of the file.
        
        The returned list will have the following format:
        
            [ { Haralick Features (52) }, { Local Binary Patterns (108) } ]
        
        """
        
        return self.haralick_features() + self.local_binary_pattern_features()
            
    def metadata_features(self):
        """Return a feature vector containing metadata related features
        extracted from the sample's hex dump.
        
        The feature vector will have the following format:
        
        [ {file size (bytes)}, {1st byte sequence address (decimal)} ]
        """
        return [self.file_size(), self.first_address()]
        
    def strings(self):
        """Return a list of all strings in the file.
        
        Strings are determined by taking by converting all of the bytes in the
        file to their ASCII equivalent characters and separating the sequence
        of characters on "unreadable" characters. In ASCII, characters in the
        range of 32 - 127 are considered readable.
        """
        
        # Check the cache for the saved strings first.
        if ('Strings' not in self):
            
            # Retrieve all of the bytes in the hex file.
            bytes = self.bytes()
            
            # The first four bytes of every 20 bytes contains an address, which
            # should not be analyzed to find a string.
            bytes = [bytes[i] for i in range(len(bytes)) if i % 20 >= 4]
            
            # Convert the hex values to decimal values.
            # NOTE: The ?? bytes are useless. Filter them out.
            ascii_values = [byte for byte in bytes if byte != -1]
            
            # The printable range for ASCII characters is 32 - 127. Replace
            # anything outside those bounds with a null to be filtered out.
            characters = [chr(value) if 32 <= value <= 127 else '\0' for value 
                          in ascii_values]
                          
            # Retrieve each string by splitting up sequences of characters by
            # null characters.
            strings = ''.join(characters)
            strings = [string for string in strings.split('\0') 
                       if string != '']
            
            # Cache the strings.
            self['Strings'] = strings
            
        return self['Strings']
        
    def string_features(self, *bins):
        """Returns a histogram containing the count of all of the strings in
        each specified bin.
        
        The bins parameter should be a list of tuples containing 2 integers
        that define the range for each bin. The first number of each tuple
        should define the lower range (inclusive) and the second number should
        define the higher range (exclusive).
        
        On top of the specified bins, there will always be a bin countaining
        the count of all strings that didn't fall into any other bins. The
        count for this bin will be the last value in the returned list.
        """
        
        # Default bin_boundaries:
        if (not bins):
            bins = [(0, 10), (10, 30), (30, 60), (60, 90), (0, 100),
                    (100, 150), (150, 250), (250, 400), (400, 600), (600, 900),
                    (900, 1300), (1300, 2000), (2000, 3000), (3000, 6000), 
                    (6000, 150000)]
                    
        # If there were specific bin values passed, ensure they are structured
        # correctly.
        else:
            
            # Validate each bin.
            for bin in bins:
                
                # Ensure each item is a tuple.
                if (type(bin) is not tuple):
                    raise TypeError('Bins must be represented with tuples')
                    
                # Ensure each tuple has only two values.
                if (len(bin) != 2):
                    raise ValueError('Bin tuples must contain exactly 2 ints')
                    
                # Ensure both values are integers.
                if (type(bin[0]) is not int or type(bin[1]) is not int):
                    raise TypeError('Bin tuples must contain int values')
                    
        # Convert each bin to a range.
        bins = [range(bin[0], bin[1]) for bin in bins]
        
        # Retrieve all of the strings.
        strings = self.strings()
        
        # Categorize each string into a bin.
        # NOTE: A single string can be classified into multiple bins.
        counts = {bin: 0 for bin in bins}
        uncategorized = 0
        for string in strings:
            
            # Keep track if a string is categorized into at least one bin.
            categorized = False
            
            # Check if the string fits in each bin.
            for bin in bins:
                
                # Count the string if its length fits in the range of the bin.
                if len(string) in bin:
                    counts[bin] += 1
                    
                # Mark the bin as categorized.
                categorized = True
                
            # Check if the string was uncategorized.
            if (not categorized):
                uncategorized += 1
                
        # Return the count for every bin.
        counts = [counts[bin] for bin in bins]
        counts.append(uncategorized)
        
        return counts
        
    def one_gram_features(self, *one_grams):
        """Return the list of frequencies in the hex file for every specified
        1-gram value.
        
        A 1-gram has 256 possible values (0 - 255). The list returned will
        contain integer values representing the number of times its respective
        1-gram appeared in the file.
        
        If no argument is specified, the frequencies of all 256 possible 
        1-grams are found. In this scenario, the 1-grams are in ascending 
        order, meaning that 0x00 is at index 0 and 0xFF is at index 255.
        """
        
        # Default one_grams:
        if not one_grams:
            one_grams = range(256)
        
        # Validate one_grams:
        else:
            
            # Type check
            non_ints = sum(type(item) is not int for item in one_grams)
            if (non_ints > 0):
                raise TypeError('1-gram values must be integer values')
                
            # Range check
            invalid_ranges = sum(not 0 <= value <= 255 for value in one_grams)
            if (invalid_ranges > 0):
                raise ValueError('1-grams must be in the range 0 - 255 '
                                 + 'inclusive')
                                                                  
        # Every byte represents a one-gram.
        # NOTE: ?? bytes are ignored.
        file_one_grams = [byte for byte in self.bytes() if byte != -1]
            
        # Retrieve the counts for each one gram.
        counts = {one_gram: 0 for one_gram in one_grams}
        for one_gram in file_one_grams:
            if (one_gram in counts):
                counts[one_gram] += 1
                
        return [counts[one_gram] for one_gram in one_grams]