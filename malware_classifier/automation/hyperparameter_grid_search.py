from ..storage import create_dirs

import csv
import itertools

def hyperparameter_grid_search(classifier_type, features, labels, 
                               results_file_name, train_ratio=0.7,
                               num_processes=4, **parameter_subsets):
    """Performs a grid search hyperparameter optimization for the specified
    classifier type and prints the results to the specified file.
    
    classifier_type should be the type of the classifier to use. The Classifier
    should have a constructor that takes a set of keyword arguments that are
    used to set the parameters for the underlying model.
    
    features should be the feature matrix for the sample set to test the
    classifier on.
    
    labels should be the list of labels for the sample set to test the
    classifier on.
    
    results_file_name should be the name of the csv file that the results 
    should be output to.
    
    train_ratio is the ratio of the included sample set to be used for
    training. The result will be used for testing.
    
    num_processes is the number of processes that can be spawned to train the
    classifiers concurrently.
    
    parameter_subsets should specify the list of values to test for each
    hyperparameter. The key for each entry should directly reference a specific
    hyperparameter in the model and each value should be a list of values to
    test for that model.
    
    Note that this function will train a model for every combination of
    hyperparameters values supplied. This function may take a very long time to
    complete. If this is stopped prematurely, the results_file will only
    contain the results for the models that were already trained.
    """
        
    # Ensure the directory for the results file exists.
    create_dirs(results_file_name)
        
    # Retrieve a list of all of the parameter keys. This is necessary to 
    # ensure that the keys are always in the same order.
    names = list(parameter_subsets.keys())
    
    # Print the headers to the file.
    with open(results_file_name, 'w') as file:
        headers = names + ['Accuracy', 'Logloss']
        csv.writer(file, lineterminator='\n').writerow(headers)
    
    # Retrieve the cartesion product of all of the sets of values.
    parameter_sets = list(itertools.product(*[parameter_subsets[key] 
                                              for key in names]))
    
    # Each set is currently a list of all of the parameters. In order to 
    # set the parameters, each list will need to be converted to a 
    # dictionary to associate the parameter names with their values.
    parameter_sets = [dict(zip(names, set)) for set in parameter_sets]
    
    print(parameter_sets)
    
    # Indicate how many classifiers need to be trained.
    print('Training %d classifiers...' % len(parameter_sets))
    
    # Test each set of parameters.
    for parameters in parameter_sets:
        
        # Train the classifier.
        classifier = classifier_type(features, labels, 
                                     training_ratio=train_ratio,
                                     **parameters)
                                     
        # Measure the performance measures of the classifier.
        accuracy = classifier.accuracy()
        logloss = classifier.logloss()
        
        row = [parameters[name] for name in names]
        row += [accuracy, logloss]
        
        # Print results to file.
        with open(results_file_name, 'a') as file:
            csv.writer(file, lineterminator='\n').writerow(row)
            
        # Indicate that a classifier has finished.
        print('Finished a classifier...')
                      
                      